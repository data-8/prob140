{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Waiting Times ###\n",
    "Let's find some expectations by conditioning. All of the calculations below involve conditioning on early moves of a random process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting till H ###\n",
    "A coin lands heads with chance $p$. Let's call it a $p$-coin for short. Let $X$ be the number of tosses of a $p$-coin till the first head appears.\n",
    "\n",
    "As you have seen in exercises, $X$ has the geometric $(p)$ distribution on $1, 2, 3, \\ldots $. By using the tail sum formula for expectation, you have showed that $E(X) = p$. Here is a quicker way to arrive at the same result.\n",
    "\n",
    "The method is based on representing $X$ as a mixture of two other random variables:\n",
    "- With probability $p$, $X=1$.\n",
    "- With the remaining probability $q = 1-p$, the first toss is a tail, and then *the process starts over* independently of what has happened before. That is, with probability $q$, $X = 1 + X^*$ where $X^*$ is an independent copy of $X$.\n",
    "\n",
    "Therefore, by averaging conditional expectations,\n",
    "\n",
    "$$\n",
    "E(X) = pE(1) ~ + ~ qE(1+X^*) = p + q(1+E(X^*)) = p + q(1+E(X))\n",
    "$$\n",
    "\n",
    "Solve for $E(X)$:\n",
    "$$\n",
    "E(X) = \\frac{1}{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting Till Both Faces Have Appeared ###\n",
    "Suppose you toss the $p$-coin until both faces have appeared. Let $N$ be the number of tosses. \n",
    "\n",
    "**Question.** What is $E(N)$?\n",
    "\n",
    "**Answer.** By conditioning on the first toss:\n",
    "- With probability $p$ the first toss is a head, so $N = 1 + W_T$ where $W_T$ has the geometric $(q)$ distribution.\n",
    "- With probability $q$ the first toss is a tail, so $N = 1 + W_H$ where $W_H$ has the geometric $(p)$ distribution.\n",
    "\n",
    "So \n",
    "\n",
    "$$\n",
    "E(N) = p\\big{(}1 + \\frac{1}{q} \\big{)} + q\\big{(}1 + \\frac{1}{p} \\big{)}\n",
    "= 1 + \\frac{p^2 + q^2}{pq} = \\frac{1 - pq}{pq}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting till HH ###\n",
    "In tosses of a $p$-coin, let $W_{HH}$ be the number of tosses till you see two heads in a row. \n",
    "\n",
    "** Question.** What is $E(W_{HH})$?\n",
    "\n",
    "**Answer 1.** We can find this is several ways. One way is by conditioning on the first two tosses.\n",
    "- With probability $q$, the first toss is a tail, so $W_{HH} = 1 + W^*$ where $W^*$ is an independent copy of $W_{HH}$.\n",
    "- With probability $pq$ the first two tosses are HT, and $W_{HH} = 2 + W^{**}$\n",
    "where $W^{**}$ is an independent copy of $W_{HH}$.\n",
    "- With probability $p^2$, the first two tosses are heads, and $W_{HH} = 2$.\n",
    "\n",
    "So if $x = E(W_{HH})$ then\n",
    "$$\n",
    "x = q(1+x) + pq(2+x) + p^22\n",
    "$$\n",
    "\n",
    "So \n",
    "$$\n",
    "x = \\frac{q + 2pq + 2p^2}{1 - q - pq} \n",
    "= \\frac{1+p}{p^2}\n",
    "$$\n",
    "by repeatedly using $p + q = 1$.\n",
    "\n",
    "**Answer 2.** Another way is by conditioning on $X$, the number of tosses till the first head. This is the same random variable $X$ as in the previous example. Notice that $W_{HH} = X + Y$ where:\n",
    "- With probability $p$, the toss after $X$ is a head, so $Y = 1$.\n",
    "- With probability $q$, the toss after $X$ is a tail, so $Y = 1 + W^*$ where $W^*$ is an independent copy of $W_{HH}$.\n",
    "\n",
    "So if $x = E(W_{HH})$ then\n",
    "$$\n",
    "x = E(X) + E(Y) = \\frac{1}{p} + p + q(1 + x)\n",
    "$$\n",
    "So\n",
    "$$\n",
    "px = \\frac{1}{p} + 1 ~~~~ \\text{and hence} ~~~~ x = \\frac{1+p}{p^2}\n",
    "$$\n",
    "as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gambler's Ruin: Duration of the Game ###\n",
    "Let's return to the setting of the gambler's ruin problem with a fair coin. The gambler starts with $\\$a$ and bets on a fair coin till he reaches either $\\$b$ or $\\$0$. Let $T$ be the duration of the game. \n",
    "\n",
    "**Question.** What is $E_a(T)$, the expected duration of the game given that the gambler starts with $\\$a$?\n",
    "\n",
    "**Answer.** Let $E_k(T)$ denote the expected duration of the game given that the gambler starts with $\\$k$. Then for $1 \\le k \\le b-1$,\n",
    "\n",
    "$$\n",
    "E_k(T) = 1 + \\frac{1}{2}E_{k-1}T + \\frac{1}{2} E_{k+1}T\n",
    "$$\n",
    "where the edge cases are\n",
    "$$\n",
    "E_0(T) = 0 = E_b(T)\n",
    "$$\n",
    "\n",
    "You can check that the function $f(k) = k(b-k)$ satisfies this recursion, and hence that $E_a(T) = a(b-a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
